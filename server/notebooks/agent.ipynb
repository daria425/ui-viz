{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e3c9700-29c0-4250-83a3-247750d2dcc6",
   "metadata": {},
   "source": [
    "The first step is to getting an AI-generated data visualization is to get a description of the dataset. This description will be used as a guide for Retrieval Augmented Generation over the <a href=\"https://airbnb.io/visx/\">visx</a> library documentation. For simplicity, we will limit the data format to CSV files. In this notebook we will use OpenAI's assistants and the code interpreter tool to get a comprehensive description of a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5d883-f090-443a-a4d0-0f62d82e1455",
   "metadata": {},
   "source": [
    "We start with importing the `openai` and `python-dotenv` libraries. An `OPENAI_API_KEY` should be defined in a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ddabb28-7483-47cf-8dde-cb1836d268de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900da561-f645-4ba7-b0d1-68919ac4e035",
   "metadata": {},
   "source": [
    "Now we need to load a sample dataset. I will be using a large sales dataset from kaggle (source: https://www.kaggle.com/datasets/seiffathi/sales-analysis-datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fa8c2-37be-490c-a65a-4b63298c0d11",
   "metadata": {},
   "source": [
    "This is what the dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b9253eb-ab0f-4925-9a3a-e010414d82e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 18383 Number of columns: 6 Column names: ['Order ID', 'Product', 'Quantity Ordered', 'Price Each', 'Order Date', 'Purchase Address']\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/sample.csv\")\n",
    "print(\"Number of rows:\",df.shape[0], \"Number of columns:\", df.shape[1], \"Column names:\",list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd0edc74-d8ea-4c3f-80ab-67ea22905bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176558</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>2</td>\n",
       "      <td>11.95</td>\n",
       "      <td>04/19/19 08:46</td>\n",
       "      <td>917 1st St, Dallas, TX 75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176559</td>\n",
       "      <td>Bose SoundSport Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>04/07/19 22:30</td>\n",
       "      <td>682 Chestnut St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176560</td>\n",
       "      <td>Google Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176560</td>\n",
       "      <td>Wired Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID                     Product Quantity Ordered Price Each  \\\n",
       "0   176558        USB-C Charging Cable                2      11.95   \n",
       "1      NaN                         NaN              NaN        NaN   \n",
       "2   176559  Bose SoundSport Headphones                1      99.99   \n",
       "3   176560                Google Phone                1        600   \n",
       "4   176560            Wired Headphones                1      11.99   \n",
       "\n",
       "       Order Date                      Purchase Address  \n",
       "0  04/19/19 08:46          917 1st St, Dallas, TX 75001  \n",
       "1             NaN                                   NaN  \n",
       "2  04/07/19 22:30     682 Chestnut St, Boston, MA 02215  \n",
       "3  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
       "4  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173e69f-0085-4074-b5c0-73e782fa129a",
   "metadata": {},
   "source": [
    "Now we need to define a prompt for the assistant to use. This prompt needs to guide the assistant to use the pandas library to inspect the uploaded CSV file and get the request description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f9d3b4ff-930c-4997-8b3f-066ac433f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions=\"\"\"\n",
    "You're a skilled Python programmer tasked with creating Python 3 solutions for analyzing pandas dataframes, following top industry practices. \n",
    "Help the user analyze their data, using code to assist yourself. \n",
    "\n",
    "Make sure your code complies with these rules:\n",
    "1. Plan first: Have a clear strategy before you start. Outline your approach if it helps.\n",
    "2. Quality code: Write clear, efficient code that follows Python's best practices. Aim for clean, easy-to-read, and maintainable code.\n",
    "3. Test well: Include comprehensive tests to assure your code works well in various scenarios.\n",
    "\n",
    "Additionally, your response must follow these guidelines:\n",
    "1. If the user asks for a visualization, suggest a method but do not write any code to visualiza the data for the user. Examples of your response may be:\n",
    "Bar chart\n",
    "Histogram\n",
    "Pie chart\n",
    "Your response may be another visualization type as well. \n",
    "2. Keep your responses to the user concise. No yapping. \n",
    "3. Only state information that directly answers the users query.\n",
    "4. Focus on what the data represents. If the user asks for a datatype of a column, infer what it should be based of column name and date. \n",
    "Example: \n",
    "column name: Order date\n",
    "column value: 04/07/19 22:30\n",
    "datatype: date\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ec2ad-2801-4cee-b490-536fc242a15c",
   "metadata": {},
   "source": [
    "Now initializing an openAI client with the prompt and sample csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c1b3fe7-21ea-4e2f-8aa6-d98662d8b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI() \n",
    "file=client.files.create(\n",
    "  file=open(\"../data/sample.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "file_id=file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "69e5737e-88a5-4ef0-9ac2-ccfe924d98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"data analyst 2\",\n",
    "  instructions=instructions,\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "temperature=0.2,\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file_id]\n",
    "    }},\n",
    "  model=\"gpt-4o\",\n",
    ")\n",
    "assistant_id=assistant.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daff896-80c6-4627-8966-4c3805ef653b",
   "metadata": {},
   "source": [
    "Now we create an empty thread. This thread will store the user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d2452a2-5b2d-4eb3-8474-623a25a66057",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread_id=thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d28e652-2cda-46ff-9811-c5b87e9697ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread_id,\n",
    "  role=\"user\",\n",
    "  content=\"Provide a summary of the dataset. List its length, the categories and their datatypes. State what the dataset represents. Suggest one data visualization method suitable for this dataset.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77be992f-0d1e-4767-89d2-8ae46a36e38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > Let's start by loading the dataset and examining its structure to provide a summary. We'll look at the first few rows, the column names, their datatypes, and the length of the dataset. This will help us understand what the dataset represents and suggest a suitable visualization method.\n",
      "assistant > code_interpreter\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "file_path = '/mnt/data/file-Ixo74dUkLx6unkqip3NIFwBg'\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Display the first few rows, column names, datatypes, and length of the dataset\n",
      "df_head = df.head()\n",
      "df_info = df.info()\n",
      "df_length = len(df)\n",
      "\n",
      "df_head, df_info, df_length\n",
      "\n",
      "output >\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18383 entries, 0 to 18382\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Order ID          18324 non-null  object\n",
      " 1   Product           18324 non-null  object\n",
      " 2   Quantity Ordered  18324 non-null  object\n",
      " 3   Price Each        18324 non-null  object\n",
      " 4   Order Date        18324 non-null  object\n",
      " 5   Purchase Address  18324 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 861.8+ KB\n",
      "\n",
      "\n",
      "assistant > ### Summary of the Dataset\n",
      "\n",
      "- **Length**: 18,383 entries\n",
      "- **Columns and Datatypes**:\n",
      "  - `Order ID`: object (should be an identifier)\n",
      "  - `Product`: object (product name)\n",
      "  - `Quantity Ordered`: object (should be integer)\n",
      "  - `Price Each`: object (should be float)\n",
      "  - `Order Date`: object (should be date)\n",
      "  - `Purchase Address`: object (address)\n",
      "\n",
      "### Dataset Representation\n",
      "The dataset appears to represent sales data, including information about orders, products, quantities, prices, order dates, and purchase addresses.\n",
      "\n",
      "### Suggested Data Visualization\n",
      "A suitable visualization method for this dataset could be a **bar chart** to show the total sales per product."
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    " \n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    " \n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    " \n",
    "# Then, we use the `stream` SDK helper \n",
    "# with the `EventHandler` class to create the Run \n",
    "# and stream the response.\n",
    " \n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread_id,\n",
    "  assistant_id=assistant_id,\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db15d9-9576-46d7-a6ae-71ae229026b7",
   "metadata": {},
   "source": [
    "The relevant information is in the last message of the thread, so we will retrieve and store this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "708c3ec0-3926-481b-9638-f821ea445d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_messages = client.beta.threads.messages.list(thread_id)\n",
    "data=thread_messages.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34760df5-994d-4971-895c-2b76aa27cddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7fab6c7-3002-4fc7-8de5-56f9063b6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message=data[0]\n",
    "last_message_content=last_message.content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c0f71e8-922f-4d7c-8cc8-d9727d4ecd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary of the Dataset\n",
      "\n",
      "- **Length**: 18,383 entries\n",
      "- **Columns and Datatypes**:\n",
      "  - `Order ID`: object (should be an identifier)\n",
      "  - `Product`: object (product name)\n",
      "  - `Quantity Ordered`: object (should be integer)\n",
      "  - `Price Each`: object (should be float)\n",
      "  - `Order Date`: object (should be date)\n",
      "  - `Purchase Address`: object (address)\n",
      "\n",
      "### Dataset Representation\n",
      "The dataset appears to represent sales data, including information about orders, products, quantities, prices, order dates, and purchase addresses.\n",
      "\n",
      "### Suggested Data Visualization\n",
      "A suitable visualization method for this dataset could be a **bar chart** to show the total sales per product.\n"
     ]
    }
   ],
   "source": [
    "print(last_message_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33879ea0-c1df-4895-a248-c973a184eea1",
   "metadata": {},
   "source": [
    "Since these runs are expensive, I was curious to see if we can use the OpenAI completions API to generate the necessary Python code and then  run this code on the local file. First we will need a prompt and a custom function. The aim of the custom function is to generate code which we will then execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0355cc-a592-405e-b46a-2bc995f32769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_function=[\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"write_pandas_code\",\n",
    "            \"description\": \"Write Python 3 Pandas script that loads the dataset from the path provided in the import text and performs analysis required by the user.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"script\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The script to perform the analysis requested by the user\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "system_prompt=\"\"\"\n",
    "You're a skilled Python programmer tasked with creating Python 3 solutions for analyzing data, following top industry practices. Your task is to write a python script that loads the file from the file path in the input text and performs the analysis requested by the user using the pandas library. Make sure that your script is executable and imports all necessary libraries.\n",
    "\"\"\"\n",
    "file_path=\"../data/sample.csv\"\n",
    "user_prompt=f\"\"\"My file is located at {file_path}. Please write a script that gets the length and size of the dataset, the column names, and their datatypes and returns them as a dictionary\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b07a6ee2-a249-4a88-8d4a-97d1de219c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "client=OpenAI() #reinitialize the client here\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ],\n",
    "    temperature=0.2, \n",
    "    tools=df_analysis_function, \n",
    "    tool_choice=\"required\"\n",
    "\n",
    ")\n",
    "response=completion.choices[0].message.tool_calls[0].function.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4548c560-8e23-4ca0-8177-f9845c95b33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\n\\ndef analyze_dataset(file_path):\\n    # Load the dataset\\n    df = pd.read_csv(file_path)\\n    \\n    # Get the length and size of the dataset\\n    length = len(df)\\n    size = df.size\\n    \\n    # Get the column names and their datatypes\\n    columns = df.columns.tolist()\\n    dtypes = df.dtypes.apply(lambda x: x.name).to_dict()\\n    \\n    # Return the results as a dictionary\\n    return {\\n        'length': length,\\n        'size': size,\\n        'columns': columns,\\n        'dtypes': dtypes\\n    }\\n\\n# Example usage\\nfile_path = '../data/sample.csv'\\nresult = analyze_dataset(file_path)\\nprint(result)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "parsed_response=json.loads(response)\n",
    "ai_code=parsed_response['script']\n",
    "ai_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c861d513-2f9c-4c53-a2aa-f45555027cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'length': 18383, 'size': 110298, 'columns': ['Order ID', 'Product', 'Quantity Ordered', 'Price Each', 'Order Date', 'Purchase Address'], 'dtypes': {'Order ID': 'object', 'Product': 'object', 'Quantity Ordered': 'object', 'Price Each': 'object', 'Order Date': 'object', 'Purchase Address': 'object'}}\n"
     ]
    }
   ],
   "source": [
    "#this is risky, there probably needs to be some guard rails around doing this but YOLO\n",
    "exec(ai_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc6363-8f44-4199-b994-4db4c4ef2ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
